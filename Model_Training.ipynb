{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab975204",
   "metadata": {},
   "source": [
    "# Intel Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f69161",
   "metadata": {},
   "source": [
    "* The image data of Natural Scenes around the world.\n",
    "* Want to build powerful Neural network that can classify these images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a31b2",
   "metadata": {},
   "source": [
    "* Categories :- This Project contained Images of the 6 different classes ('buildings','forest','glacier','mountain','sea', 'street').\n",
    "\n",
    "* seg_train and seg_test which are contained in a folder called classification which holds training and testing images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff88e716",
   "metadata": {},
   "source": [
    "kaggle Dataset Link :- https://www.kaggle.com/puneet6060/intel-image-classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b7a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4098f",
   "metadata": {},
   "source": [
    "In the above line of Code, we have implented all the libraries which Required to build a Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39d079",
   "metadata": {},
   "source": [
    "### Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4919bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(100, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Conv2D(100, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(6, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c24bec",
   "metadata": {},
   "source": [
    "* In the above line, We have implented our Neural Network.\n",
    "* This Neural network having different Layes of Neurons , Like 100 Neurons, 50 Neurons & at the output 6 Neurons.\n",
    "* Activation function in Starting layes we used 'RELU' and at the Last layes we used 'Softmax' Activation Function.\n",
    "* Optimizer that we have used is \"Adam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a02865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg_train/seg_train\n",
      "Found 14034 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = \"seg_train/seg_train\"\n",
    "print(TRAINING_DIR)\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=20,\n",
    "                                                    target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3172465",
   "metadata": {},
   "source": [
    "* ImageDataGenerator = It is used to Expand the dataset in otder to improve the Performance & ability of the model to generalize.\n",
    "* Flow_From_Directory = This method will Identify Classes automatically from the given Folder.\n",
    "* Rescale = It is used to convert the values of Matrix in Between range 0 to 1.\n",
    "* Batch_Size = Insted of sending whole dataset for Training , we send them in the Form of Batches for better calculation.\n",
    "* Target_Size = Set the Fixed size for all the Images. \n",
    "* TRAINING_DIR = Get the Dataset from this Directory for Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2758e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg_test/seg_test\n",
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_DIR = \"seg_test/seg_test\"\n",
    "print(VALIDATION_DIR)\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=20,\n",
    "                                                              target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db36140",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model2-{epoch:03d}.model', monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                             mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de55be",
   "metadata": {},
   "source": [
    "* ModelCheckpoint = 'ModelCheckpoint' callback is used in conjuction with training using model.fit() to save a Model or Weight (In a CheckPoint File) at some Interval, so Model or Weight can be Loaded later to continue the Training from the state saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ae4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meabh\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "702/702 [==============================] - 538s 766ms/step - loss: 1.2159 - acc: 0.5155 - val_loss: 1.0927 - val_acc: 0.5690\n",
      "INFO:tensorflow:Assets written to: model2-001.model\\assets\n",
      "Epoch 2/15\n",
      "702/702 [==============================] - 536s 763ms/step - loss: 1.0058 - acc: 0.6170 - val_loss: 0.9980 - val_acc: 0.6450\n",
      "INFO:tensorflow:Assets written to: model2-002.model\\assets\n",
      "Epoch 3/15\n",
      "702/702 [==============================] - 549s 783ms/step - loss: 0.9484 - acc: 0.6386 - val_loss: 0.7804 - val_acc: 0.7213\n",
      "INFO:tensorflow:Assets written to: model2-003.model\\assets\n",
      "Epoch 4/15\n",
      "702/702 [==============================] - 1085s 2s/step - loss: 0.8748 - acc: 0.6721 - val_loss: 0.7179 - val_acc: 0.7443\n",
      "INFO:tensorflow:Assets written to: model2-004.model\\assets\n",
      "Epoch 5/15\n",
      "702/702 [==============================] - 1927s 3s/step - loss: 0.8116 - acc: 0.6985 - val_loss: 0.8244 - val_acc: 0.6957\n",
      "Epoch 6/15\n",
      "702/702 [==============================] - 1088s 2s/step - loss: 0.7881 - acc: 0.7074 - val_loss: 0.6375 - val_acc: 0.7757\n",
      "INFO:tensorflow:Assets written to: model2-006.model\\assets\n",
      "Epoch 7/15\n",
      "702/702 [==============================] - 1088s 2s/step - loss: 0.7626 - acc: 0.7168 - val_loss: 0.5865 - val_acc: 0.7923\n",
      "INFO:tensorflow:Assets written to: model2-007.model\\assets\n",
      "Epoch 8/15\n",
      "702/702 [==============================] - 918s 1s/step - loss: 0.7412 - acc: 0.7241 - val_loss: 0.6070 - val_acc: 0.7870\n",
      "Epoch 9/15\n",
      "702/702 [==============================] - 575s 819ms/step - loss: 0.7194 - acc: 0.7336 - val_loss: 0.5835 - val_acc: 0.7917\n",
      "INFO:tensorflow:Assets written to: model2-009.model\\assets\n",
      "Epoch 10/15\n",
      "702/702 [==============================] - 577s 822ms/step - loss: 0.7197 - acc: 0.7369 - val_loss: 0.6202 - val_acc: 0.7843\n",
      "Epoch 11/15\n",
      "702/702 [==============================] - 559s 796ms/step - loss: 0.6991 - acc: 0.7446 - val_loss: 0.6040 - val_acc: 0.7823\n",
      "Epoch 12/15\n",
      "702/702 [==============================] - 560s 798ms/step - loss: 0.6841 - acc: 0.7438 - val_loss: 0.6211 - val_acc: 0.7900\n",
      "Epoch 13/15\n",
      "702/702 [==============================] - 560s 798ms/step - loss: 0.6807 - acc: 0.7484 - val_loss: 0.5485 - val_acc: 0.8110\n",
      "INFO:tensorflow:Assets written to: model2-013.model\\assets\n",
      "Epoch 14/15\n",
      "702/702 [==============================] - 614s 875ms/step - loss: 0.6604 - acc: 0.7554 - val_loss: 0.6447 - val_acc: 0.7770\n",
      "Epoch 15/15\n",
      "702/702 [==============================] - 569s 810ms/step - loss: 0.6619 - acc: 0.7620 - val_loss: 0.5853 - val_acc: 0.7943\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=15,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ca71c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ImageClassification_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(r'ImageClassification_model') #saved the  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30851f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
